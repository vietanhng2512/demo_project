import cv2
import numpy as np
import matplotlib.pyplot as plt

plt.rcParams['figure.figsize'] = [12, 8]
Img_xray = cv2.imread("xray.jpeg",0)
# cv2.imshow("Anh",Img_xray)
plt.imshow(Img_xray, cmap="gray")
plt.show()

# Image negatives
# Ta c√≥ th·ªÉ chuy·ªÉn t·ª´ ·∫£nh b√™n tr√°i sang b√™n ph·∫£i ( ƒë·ªïi ƒëen th√†nh tr·∫Øng v√† tr·∫Øng th√†nh ƒëen üòÉ)
negation = 255 - Img_xray
plt.imshow(negation, cmap="gray")
plt.show()

# plot a quantization image of k level
def draw_quantization_img(levels, height = 32):
    # convert it to an image
    Img = [levels] * height
    img = np.array(Img)
    plt.imshow(Img, "gray")
    #plt.axis('off')
    return img

gray_256 = list(range(0, 256, 1))
draw_quantization_img(gray_256)
plt.show()

gray_64 = list(range(0, 256, 4))
print(len(gray_64))
draw_quantization_img(gray_64, height= 8)
plt.title("64", loc= "left")
plt.show()

gray_32 = list(range(0, 256, 8))
print(len(gray_32))
draw_quantization_img(gray_32, height= 4)
plt.title("32", loc= "left")
plt.show()

gray_16 = list(range(0, 256, 16))
print(len(gray_16))
draw_quantization_img(gray_16, height= 2)
plt.title("16", loc= "left")
plt.show()

gray_8 = list(range(0, 256, 32))
print(len(gray_8))
draw_quantization_img(gray_8, height= 2)
plt.title("8", loc= "left")
plt.show()

# Gamma
# vout=vŒ≥in
# vin  : ƒë·ªô s√°ng th·ª±c t·∫ø (actual luminance value)
#
# vout : ƒë·ªô s√°ng c·∫£m nh·∫≠n (output luminance value)
def adjust_gamma(inlevels, gamma= 1.0, debug= True):
    out = [l ** gamma for l in inlevels]
    max_out = max(out)
    out = [int(l/max_out * 256) for l in out]
    print(out)
    return out

# Kh√¥ng ƒëi·ªÅu ch·ªânh gamma(no adjustment)
draw_quantization_img(
    # Cho d·∫£i m√†u x√°m 16 m·ª©c, v·ªõi gamma = 1 th√¨ n√≥ s·∫Ω gi·ªØ nguy√™n nh∆∞ sau:
    adjust_gamma(gray_16, gamma= 1),
    height = 2
)
plt.title("[0, 17, 34, 51, 68, 85, 102, 119, 136, 153, 170, 187, 204, 221, 238, 256]", loc="left")
plt.show()

# V·ªõi gamma > 1, ta th·∫•y n·∫øu gi√° tr·ªã ƒë·∫ßu v√†o l√† t·ªëi (th·∫•p) th√¨ ƒë·∫©u ra l√† t·ªëi h∆°n,
# v√≠ d·ª• ƒë·∫ßu v√†o l√† gi√° tr·ªã 17 th√¨ ƒë·∫ßu ra l√† gi√° tr·ªã 0:
# with gamma > 1, the levels are shifted toward to the darker end of the spectrum
draw_quantization_img(
    adjust_gamma(gray_16, gamma= 2.2),
    height = 2
)
plt.title("[0, 0, 3, 7, 13, 22, 34, 47, 64, 83, 104, 129, 156, 186, 219, 256]", loc= "left")
plt.show()

# V·ªõi gamma < 1, c√°c gi√° tr·ªã ƒë·∫ßu v√†o l√† th·∫•p th√¨ ƒë·∫©u ra s√°ng h∆°n,
# v√≠ d·ª• ƒë·∫ßu v√†o l√† 17 ƒë·∫ßu ra l√† gi√° tr·ªã 74:
# with gamma < 1, lighter
draw_quantization_img(
    adjust_gamma(gray_16, gamma= 1/ 2.2, debug= "True"),
    height = 2
)
plt.title("[0, 74, 102, 123, 140, 155, 168, 181, 192, 202, 212, 222, 231, 239, 248, 256]", loc= "left")
plt.show()

# Logarithmic graph
x = np.arange(0, 1.2, 0.01)

g1 = np.power(x, 1)
g2 = np.power(x, 2.2) # gamma = 2.2
g3 = np.power(x, 5) # gamma = 5
g4 = np.power(x, 1/2.2)
g5 = np.power(x, 1/5)

fig, ax = plt.subplots()
ax.plot(x, g1, "r", label = "Linear")
ax.plot(x, g2, "b--", label = "gamma = 2.2")
ax.plot(x, g3, "b:", label = "gamma = 5")
ax.plot(x, g4, "g+", label = "gamma = 1/2.2")
ax.plot(x, g5, "g.", label = "gamma = 1/5")

ax.set_xlim([0, 1.2])
ax.set_ylim([0, 1.2])
legend = ax.legend(loc= "upper left", fontsize= "x-large")

plt.rcParams['figure.figsize'] = [8, 8]
plt.show()

# S·ª≠ d·ª•ng gamma ƒë·ªÉ ƒëi·ªÅu ch·ªânh ƒë·ªô t∆∞∆°ng ph·∫£n
# 1. ƒê·ªô t∆∞∆°ng ph·∫£n th·∫•p (Low exposure)
# Using gamma to adjust contrast
# 1. Low exposure
low_contrast = cv2.imread("dark.jpg")
plt.imshow(low_contrast[:,:,::-1])
plt.show()

def adjust_image_gamma(Img_xray, gamma = 1.0):
    img = np.power(Img_xray, gamma)
    max_val = np.max(img.ravel())
    img = img/max_val * 255
    img = img.astype(int)
    return img

low_adjust = adjust_image_gamma(low_contrast, 0.45)
plt.imshow(low_adjust[:,:,::-1])
plt.show()

# N·∫øu nh∆∞ gamma qu√° nh·ªè th√¨ sao ?
# what if gama if too low
low_adjusted = adjust_image_gamma(low_contrast, 0.1)
plt.imshow(low_adjusted[:,:,::-1])
plt.show()

# Ta th·ª≠ ƒëo th·ªùi gian v·ªõi h√†m adjust_image_gamma:
# timeit
# low_adjusted = adjust_image_gamma(low_contrast,0.1)
# print("Th·ªùi gian:",low_adjusted)

# N√≥ r·∫•t t·ªën th·ªùi gian, c√≥ c√°ch n√†o nhanh h∆°n kh√¥ng ?. Th·∫≠t ra l√† c√≥ üòÉ. N√≥ s·∫Ω nh∆∞ sau:
# faster way to compute
# reference: https://www.pyimagesearch.com/2015/10/05/opencv-gamma-correction/
def adjust_image_gamma_lookuptable(img, gamma = 1.0):
    # build a lookup table mapping the pixel values [0, 255] to
    # their adjusted gamma values
    table = np.array([((i/ 255.0) ** gamma) * 255
        for i in np.arange(0, 256)]).astype("uint8")

    # apply gamma correction using the lookup table
    # √ù t∆∞·ªüng ·ªü ƒë√¢y l√† d√πng b·∫£ng chuy·ªÉn look-up table (LUT) s·ª≠ d·ª•ng h√†m cv2.LUT().
    return cv2.LUT(img, table)

low_adjust = adjust_image_gamma_lookuptable(low_contrast, 0.45)
plt.imshow(low_adjust[:,:,::-1])
plt.show()

# Th·ªùi gian ch·∫°y v·ªõi h√†m n√†y s·∫Ω l√† :
# timeit
# adjust_image_gamma_lookuptable(low_contrast, 0.45)
# print("Th·ªùi gian: ",adjust_image_gamma_lookuptable(low_contrast))

# 2. ƒê·ªô t∆∞∆°ng ph·∫£n cao (Overexposure)
# V·ªõi tr∆∞·ªùng h·ª£p n√†y th√¨ ta c·∫ßn gi·∫£m ƒë·ªô s√°ng xu·ªëng, hay tƒÉng ƒë·ªô t·ªëi. V√¨ v·∫≠y, s·ª≠ d·ª•ng gamma > 1:
# Overexposure
high_contrast = cv2.imread("high-exposure.jpg")
plt.imshow(high_contrast[:,:,::-1])
plt.show()

# ·ªû ƒë√¢y s·ª≠ d·ª•ng gamma = 4.
adjusted_high = adjust_image_gamma_lookuptable(high_contrast,4)
plt.imshow(adjusted_high[:,:,::-1])
plt.show()

# 2.3. Correct using pixel transform
# Reference: https://docs.opencv.org/3.4/d3/dc1/tutorial_basic_linear_transform.html
#
# D√πng ph√©p to√°n nh√¢n v√† c·ªông  g(x)=Œ±f(x)+Œ≤
#
# Œ±  v√†  Œ≤  c√≤n ƒë∆∞·ª£c g·ªçi l√† tham s·ªë gain v√† bias, ho·∫∑c tham s·ªë ƒë·ªÉ ƒëi·ªÅu ch·ªânh contrast (ƒë·ªô t∆∞∆°ng ph·∫£n) v√† brightness (ƒë·ªô s√°ng)
#
# V·ªõi ·∫£nh s·ªë:  g(i,j)=Œ±‚ãÖf(i,j)+Œ≤
def pixel_transform(img, alpha = 1.0, beta = 0):
    """
    out[pixel] = alpha * image[pixel] + beta
    """
    output = np.zeros(img.shape, img.dtype)
    h, w, ch = img.shape
    for y in range(h):
        for x in range(w):
            for c in range(ch):
                output[y, x, c] = np.clip(alpha * img[y, x, c] + beta, 0, 255)

    return output

transformed_high = pixel_transform(high_contrast, 0.5, 20)
plt.imshow(transformed_high[:,:,::-1])
plt.show()

# C√≥ m·ªôt c√°ch d√πng th∆∞ vi·ªán c·ªßa opencv ƒë·ªÉ nhanh h∆°n:
# anyway, a faster
transformed_high = cv2.convertScaleAbs(high_contrast, 20, 0.5)
plt.imshow(transformed_high[:,:,::-1])
plt.show()

# compare time
# pixel_transform(high_contrast, 0.5, 20)
# print(pixel_transform(high_contrast))

# time = % timeitcv2.convertScaleAbs(high_contrast, 20, 0.5)
# print(time)

# 2.4. Point operations for combining images
# 2.4.1. Image averaging for noise reduction
origin_img = cv2.imread("lena.jpg",0)
plt.imshow(origin_img, cmap= "gray")
plt.show()

# now make several image from noisy
def generate_noise_img(img, mean = 0, sigma = 0):
    gaussian = np.random.normal(mean, sigma, img.shape)
    noisy_img = img + gaussian
    return noisy_img

def make_batch(img, num_output = 4):
    sigmas = np.random.rand(num_output) * 2
    #print(sigmas)
    noisy_imgs = [generate_noise_img(img, sigma = sigma) for sigma in sigmas]
    return noisy_imgs

# make 4 images
noisy_Imgs = make_batch(origin_img, num_output= 4)
noisy_images = np.array(noisy_Imgs)
denoised = np.mean(noisy_images, axis= 0)
plt.imshow(denoised, cmap= "gray")
plt.show()

# Combining images
# 1. Combination of different exposures for high-dynamic range imaging
# Ta c√≥ 4 ·∫£nh v·ªõi 4 ƒë·ªô s√°ng kh√°c nhau:
# 2.4.2. Combination of different exposures for high-dynamic range imaging
hdr_1 = cv2.imread("./img_hdr/hdr1.jpeg")
hdr_2 = cv2.imread("./img_hdr/hdr2.jpeg")
hdr_3 = cv2.imread("./img_hdr/hdr3.jpeg")
hdr_4 = cv2.imread("./img_hdr/hdr4.jpeg")

Stack_img = np.stack([hdr_1,hdr_2,hdr_3,hdr_4], axis = 0)
print(Stack_img.shape)

plt.rcParams['figure.figsize'] = [12, 8]
for i in range(4):
    plt.subplot(2, 2, i + 1)
    plt.imshow(Stack_img[i][:,:,::-1])
plt.show()

# Ta s·∫Ω k·∫øt h·ª£p t√≠nh gi√° tr·ªã trung b√¨nh ƒë·ªÉ t·∫°o ra 1 ·∫£nh m·ªõi ƒë·∫πp h∆°n.
# Averaging to enhance contrast
hdr = np.mean(Stack_img, axis = 0)
HDR = hdr.astype(int)
plt.rcParams['figure.figsize'] = [8, 8]
plt.imshow(HDR[:,:,::-1])
plt.show()

# ƒê·ªëi v·ªõi ai t√≤ m√≤
# Reference: https://www.learnopencv.com/high-dynamic-range-hdr-imaging-using-opencv-cpp-python/
#
# Bao g·ªìm:
#
# CƒÉn ch·ªânh s·ª≠ d·ª•ng AlignMTB
# Thu·∫≠t to√°n chuy·ªÉn ƒë·ªïi t·∫•t c·∫£ c√°c h√¨nh ·∫£nh th√†nh bitmap ng∆∞·ª°ng trung b√¨nh (MTB)
# M·ªôt MTB cho h√¨nh ·∫£nh ƒë∆∞·ª£c t√≠nh b·∫±ng c√°ch g√°n gi√° tr·ªã 1 cho pixel s√°ng h∆°n ƒë·ªô ch√≥i trung b√¨nh v√† 0 n·∫øu kh√°c
# An MTB is invariant to the exposure time.
# Therefore, the MTBs can be aligned without requiring us to specifying the exposure time
alignMTB = cv2.createAlignMTB()
alignMTB.process(Stack_img, Stack_img)
# Obtain Camera Response Function (CRF)
# exposure time of each image, known from metadata
times = np.array([1/ 30.0, 0.25, 2.5, 15.0], dtype= np.float32)
calibrateDebevec = cv2.createCalibrateDebevec()
responseDebevec = calibrateDebevec.process(Stack_img, times)

mergeDebevec = cv2.createMergeDebevec()
hdrDebevec = mergeDebevec.process(Stack_img, times, responseDebevec)
plt.imshow(hdrDebevec[:,:,::-1])
plt.show()

# Tone mapping = Converting a HDR image to an 8-bit per channel image
# using HDR, the relative brightness information was recovered
# we need to convert the information as a 24-bit image for display
# Common parameters of the different tone mapping algorithms
# 1. gamma. For gamma correction; gamma < 1 darkens the image; gamma >1 brightens the image
# 2. saturation: to increase or decrease the amount of saturation. Higher -> colors are richer and more intense
#     Closer to zero, colors fade away to grayscale
# 3. contrast: controls the contrast. = log(maxPixelvalue/minPixelvalue)

# Opencv implements 4 tone mapping

# Tonemap using Drago's method to obtain 24-bit color image
tonemapDrago = cv2.createTonemapDrago(1.0, 0.7)
ldrDrago = tonemapDrago.process(hdrDebevec)
LDR_Drago = 3 * ldrDrago
plt.imshow(LDR_Drago[:,:,::-1])
plt.show()
# cv2.waitKey(0)
